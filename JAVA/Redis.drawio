<mxfile host="app.diagrams.net" modified="2023-12-05T03:57:53.795Z" agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36" etag="sZNPMTjs6rOQs3F3TZtX" version="22.1.5" type="github">
  <diagram name="第 1 页" id="Ui-6xDZG4yXv-m0ysYRE">
    <mxGraphModel dx="2206" dy="1166" grid="1" gridSize="10" guides="1" tooltips="1" connect="1" arrows="1" fold="1" page="1" pageScale="1" pageWidth="827" pageHeight="1169" math="0" shadow="0">
      <root>
        <mxCell id="0" />
        <mxCell id="1" parent="0" />
        <mxCell id="iayUrk5L2lRTLvckCghS-1" value="redis有几种存储形式？底层存储是怎样的数据结构？&lt;br&gt;&lt;br&gt;redis为什么快？单线程为什么快？为什么设计成单线程呢？&lt;br&gt;&lt;br&gt;redis的架构模型" style="rounded=0;whiteSpace=wrap;html=1;fontSize=18;align=left;verticalAlign=top;" parent="1" vertex="1">
          <mxGeometry x="100" y="160" width="720" height="160" as="geometry" />
        </mxCell>
        <mxCell id="iayUrk5L2lRTLvckCghS-2" value="redis的持久化有哪些？&lt;br&gt;&lt;br&gt;rdb和aof的优缺点有哪些？&lt;br&gt;&lt;br&gt;混合模式是怎样操作的呢（具体的流程）？&lt;br&gt;&lt;br&gt;redis什么时候用到了写时复制的原理？（主从复制的时候？cluster模式下增加节点的时候？）" style="rounded=0;whiteSpace=wrap;html=1;fontSize=18;align=left;verticalAlign=top;" parent="1" vertex="1">
          <mxGeometry x="100" y="380" width="790" height="170" as="geometry" />
        </mxCell>
        <mxCell id="iayUrk5L2lRTLvckCghS-3" value="redis的高可用有哪些方式呢？（主从、哨兵、cluster集群）&lt;br&gt;&lt;br&gt;redis是往分布式的哪方面进行设计的CAP中的AP？&lt;br&gt;&lt;br&gt;主从需要几个节点呢？这个节点数量貌似没有要求，至少得有1个从节点吧？&lt;br&gt;&lt;br&gt;主从的数据是怎么同步的呢？如何保证主从数据同步不会出现丢失数据的情况？&lt;br&gt;&lt;br&gt;如果只有主从，那么主节点挂掉了之后，是需要手动找一个从节点来升级成主节点？那期间的程序访问redis就不可用了？&lt;br&gt;&lt;br&gt;那么就加哨兵来保证自动故障转移？哨兵是怎么一个运作模式呢？哨兵节点的数量有没有要求呢？哨兵的作用是在出现故障时候，进行自动选主？那么涉及到选主，就建议节点的数量是奇数个，但是也不一定。你要偶数个也没问题，2个、3个、4个都行？反正要超过半数以上的节点选举成功才行。&lt;br&gt;哨兵自己也是主备架构，它自己也有单点故障的风险，那么一旦挂掉一个，也需要进行选主的操作。&lt;br&gt;&lt;br&gt;哨兵选举的过程流程是怎样的呢？节点间的通信机制是怎样的呢？socket？使用了哪些协议？gossp？不管是哨兵还是cluster，节点之间是不是都需要有心跳机制？&lt;br&gt;&lt;br&gt;当主从出现故障的时候，这时候，" style="rounded=0;whiteSpace=wrap;html=1;fontSize=18;align=left;verticalAlign=top;" parent="1" vertex="1">
          <mxGeometry x="100" y="610" width="1080" height="430" as="geometry" />
        </mxCell>
        <mxCell id="iayUrk5L2lRTLvckCghS-4" value="redis的缓存淘汰策略有哪些？LRU算法是什么？操作系统是不是也有一个LRU算法？&lt;br&gt;&lt;br&gt;redis cluster如何解决key偏向的问题。可能大量请求key都打到同一个服务器了。" style="rounded=0;whiteSpace=wrap;html=1;fontSize=18;align=left;verticalAlign=top;" parent="1" vertex="1">
          <mxGeometry x="1000" y="380" width="720" height="160" as="geometry" />
        </mxCell>
        <mxCell id="iayUrk5L2lRTLvckCghS-5" value="cluster集群模式，&lt;br&gt;&lt;br&gt;cluster模式建议最多不超过多少个主备集群呢？可能是因为集群之间是需要进行通信的，太多节点，通信压力也大。&lt;br&gt;&lt;br&gt;cluster模式，建议使用奇数个主节点（主备集群）？不是必须使用奇数个节点，因为只需要半数以上就行了，4个挂一个需要2个节点选举同一个slave节点，3个也是一样，这样奇数可以少用一个节点，当然，多一个节点可以分担一下整个集群的压力。&lt;br&gt;&lt;br&gt;节点间的通信是怎么样的？当某一个主节点发生宕机的情况，如何发起重新选举的操作呢？大概有一套流程，slave节点都会发消息给大集群内的所有节点，只有其它的主节点会返回消息，且只会返回收到的第一个消息，这样slave节点就可以在收到返回消息之后进行计数，超过一般直接自己升级为master。&lt;br&gt;&lt;br&gt;那集群发生脑裂是什么情况？脑裂会导致什么问题呢？（当主节点跟集群内所有的节点都不能通信了，但是能够跟客户端进行通信，这时候slave节点会进行选主操作重新又来一个主节点，这样某一个节点上就有2个主节点，就叫做脑裂，这时候客户端继续跟老的主节点通信操作数据，一旦老节点恢复网络通信，这时候发现集群里面已经有一个主节点了，那么这个老节点就自动成为slave，重要的是，根据主备数据同步原理，节点新加入集群，就需要进行数据全量同步，这时候，就会把老节点跟客户端在脑裂期间的数据都覆盖掉，对用户来说就少了数据&lt;br&gt;！！！），&amp;nbsp; 怎么应对脑裂呢？&lt;br&gt;&lt;br&gt;当进行节点增加时候，只需要执行一行语句，就可以增加一个节点，但是还需要进行槽位的分配，和数据的迁移，那么迁移和客户端操作会不会有冲突呢？这时候redis会进行阻塞等待吗？我猜测应该不会，可能会用到写时复制的原理？" style="rounded=0;whiteSpace=wrap;html=1;fontSize=18;align=left;verticalAlign=top;" parent="1" vertex="1">
          <mxGeometry x="93.5" y="1100" width="1126.5" height="460" as="geometry" />
        </mxCell>
        <mxCell id="iayUrk5L2lRTLvckCghS-6" value="分布式锁&lt;br&gt;&lt;br&gt;为什么需要分布式锁？&lt;br&gt;&lt;br&gt;分布式锁的实现方式（redis、zookepper、数据库）&lt;br&gt;&lt;br&gt;redis实现分布式锁的方式：setnx、redisson（框架）&lt;br&gt;&lt;br&gt;其中如果用setnx，需要自己处理很多的复杂情况：代码原子性、释放锁的时机问题、超时时间设置的长短。&lt;br&gt;&lt;br&gt;那么redission很好的封装了这些复杂的逻辑。包括锁的续期。&lt;br&gt;&lt;br&gt;当并发抢锁时候，redisson用lua脚本来执行原子性的命令，redis执行命令也是单线程执行的，所以，只会有1个线程能够抢到锁，相当于我们自己写程序用的setnx。 锁的过期时间默认30s，抢完锁就继续执行业务逻辑，这时候后台会用方法递归的方式来进行锁的续期，默认30/3=10s钟一次。其它等待的线程进行while自旋获取锁操作，先会进入阻塞状态，让出CPU的执行时间片，这个等待的时间，就是锁的过期时间TTL。如果线程执行很快，那么等待的这些线程就需要被唤醒继续抢锁，reddison利用了redis的发布订阅机制来进行唤醒的。&lt;br&gt;&lt;br&gt;redisson那些地方设计很好？&lt;br&gt;lua脚本原子性执行、线程阻塞，过期时间使用TTL、使用递归的方式来进行续期、发布订阅来唤醒所有的线程。&lt;br&gt;看门狗逻辑就是锁续命？" style="rounded=0;whiteSpace=wrap;html=1;fontSize=18;align=left;verticalAlign=top;" parent="1" vertex="1">
          <mxGeometry x="93.5" y="1580" width="946.5" height="470" as="geometry" />
        </mxCell>
        <mxCell id="_cNctXotL4sYTQS76gGQ-1" value="分布式锁，在主从架构下面的失效问题。&lt;br&gt;主从同步期间，主节点宕机。setnx的命令还没同步到从节点呢。&lt;br&gt;可以参考zookeper，CAP中的CP，半数节点以上同步完主从数据之后，才返回给客户端命令执行成功，在这之后如果主节点宕机，那么集群选主，会在已经同步完成的那些从节点之中选举。&lt;br&gt;&lt;br&gt;那redis怎么来解决呢？redlock红锁？红锁也还是会有问题的（只要红锁集群不搞从节点就行，但是都用上红锁了，肯定高可用是要考虑的），但是这种解决问题，牺牲了高可用性。（跟持久化的问题一样，每条命令都持久化，很耗费性能。推荐1s Aof）" style="rounded=0;whiteSpace=wrap;html=1;fontSize=18;align=left;verticalAlign=top;" parent="1" vertex="1">
          <mxGeometry x="100" y="2090" width="870" height="280" as="geometry" />
        </mxCell>
        <mxCell id="_cNctXotL4sYTQS76gGQ-2" value="锁优化：&lt;br&gt;分段锁：参考concurryhashmap（1.7版本），联合redisson怎么实现？。比如常规的锁，setnx apple18&amp;nbsp; 1，这个value 1是随便写的。所有的线程都会抢这一个key，那么如果我这个apple18有1000个名额优惠，就可以分成10段，setnx apple18_100 1，setnx apple18_200 1，......setnx apple18_1000 1，客户端可以进行随机、权重、轮训等方式去抢这10个锁，这样，并发就降低了10倍。但是有个问题就是，如何去控制数量呢？" style="rounded=0;whiteSpace=wrap;html=1;fontSize=18;align=left;verticalAlign=top;" parent="1" vertex="1">
          <mxGeometry x="110" y="2410" width="880" height="170" as="geometry" />
        </mxCell>
        <mxCell id="oPHmPLFePxrs62uWGmC0-1" value="redis的实战优化：&lt;br&gt;&lt;br&gt;1.所有的数据如果都存redis，肯定会很占用内存，需要加一个过期时间，一般为24小时。如果24小时有访问，则再续期24小时。这样能区分开热点数据进行缓存。&lt;br&gt;&lt;br&gt;2.缓存击穿（失效）：有种业务场景，后台操作人员，进行批量上线操作，这时候，在缓存里面的过期时间是一样的，如果刚好在失效的时候全部来访问（大促销），这时候巨量的访问都会直接导数据库上面。&lt;br&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;&#x9;&lt;/span&gt;解决方案：在上线操作的时候，过期时间：24小时+随机几个小时。这样就不会在同一时间失效了。&lt;br&gt;&lt;br&gt;3.缓存穿透：场景：1.黑客攻击（找数据库和缓存都没有的key进行访问）。2.误操作删除数据（包括数据库和缓存都删了）。这种情况就是缓存和数据库都找不到数据。、&lt;br&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;&#x9;&lt;/span&gt;解决方案：1.当缓存和数据库都没有找到数据时，在缓存里面设置一个空的对象（非null），&lt;br&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;&#x9;&lt;/span&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;&#x9;&lt;/span&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;&#x9;&lt;/span&gt;2.布隆过滤器。&lt;br&gt;&lt;br&gt;4.缓存雪崩：场景：1.redis挂了。2.大量并发请求打到redis，或者大量并发访问大key，超过负载，最后请求大量到达数据库，导致全局雪崩。&lt;br&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;&#x9;&lt;/span&gt;解决方案：1.redis集群，保证高可用。2.限流，前端nginx限流、微服务组件限流。3.多级缓存。nginx+lua+静态页面、redis缓存、jvm缓存。其中jvm缓存大公司都是用的一个项目去做热点缓存更新？&lt;br&gt;&lt;br&gt;4.分布式锁的用途：&lt;br&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;&#x9;&lt;/span&gt;1.当高并发来到首次查询的逻辑时，缓存里面没有数据，全部都会集中到数据库，不太好。&lt;br&gt;所以可以用分布式锁，分布式锁的key需要细粒化，比如细粒化到商品ID。&lt;br&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;&#x9;&lt;/span&gt;2.缓存数据库双写不一致问题的解决。&lt;br&gt;&lt;br&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;&#x9;&lt;/span&gt;上面如果加上分布式锁，会有效率问题，怎么优化分布式锁呢？&lt;br&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;&#x9;&lt;/span&gt;1.redisson的读写锁，针对双写不一致的分布式锁解决方案。&lt;br&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;&#x9;&lt;/span&gt;2.redisson的一些特殊的方法。trygetkey。" style="rounded=0;whiteSpace=wrap;html=1;fontSize=18;align=left;verticalAlign=top;" parent="1" vertex="1">
          <mxGeometry x="111" y="2720" width="939" height="610" as="geometry" />
        </mxCell>
        <mxCell id="7Gq7ySSlHzUSGOugI9tr-1" value="什么是布隆过滤器，作用是什么？" style="rounded=0;whiteSpace=wrap;html=1;fontSize=18;align=left;verticalAlign=top;" vertex="1" parent="1">
          <mxGeometry x="1188" y="2700" width="880" height="170" as="geometry" />
        </mxCell>
      </root>
    </mxGraphModel>
  </diagram>
</mxfile>
